{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X,y,seed=None):\n",
    "    '''将X和y的数据进行随机排序/乱序化'''\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    idx=np.arange(X.shape[0])\n",
    "    print(type(idx))\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx],y[idx] # 对于np.array, idx作为index数组可以改变array的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, shuffle=True, seed=None):\n",
    "    '''将数据集根据test_size分成训练集和测试集，可以知道是否随机洗牌'''\n",
    "    if shuffle:\n",
    "        X,y=shuffle_data(X, y, seed)\n",
    "        split_i=len(y)-int(len(y)//(1/test_size))\n",
    "        # split_i=len(y)-int(len(y)*test_size)\n",
    "        X_train, X_test = X[:split_i], X[split_i:]\n",
    "        y_train, y_test = y[:split_i], y[split_i:]\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=1, noise=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "应为使用make_regression函数是的X乱序，在绘制matplotlib的图像时会有问题，所以对X进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=sorted([(X_test[i][0], y_test[i]) for i in range(len(X_test))], key=lambda j:j[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.1485917382007333, 2.7703825824055777),\n",
       " (-0.9938200216244854, -55.68151401208429),\n",
       " (-0.9138580100515106, -4.885337323596332),\n",
       " (-0.741578991847208, -15.9161830633986),\n",
       " (-0.7044125041565268, -34.369442076112435),\n",
       " (-0.5498877262165497, 3.2407254271231043),\n",
       " (-0.3663853941852142, -23.144812061753104),\n",
       " (-0.11977576761835255, 11.250253908243003),\n",
       " (0.013477997985776253, 26.001772562918397),\n",
       " (0.02699858768638548, 47.305429311752135),\n",
       " (0.07697487811796382, 19.239163110565865),\n",
       " (0.20873524811319116, -13.209220217114826),\n",
       " (0.22425904173136332, -1.8068759974493531),\n",
       " (0.2585894193684694, 34.56178297426471),\n",
       " (0.2796704944956111, 20.957279256622314),\n",
       " (0.3010333923476699, 19.933648868387415),\n",
       " (0.8617184397944502, 4.592855466487936),\n",
       " (0.8925095329902133, -10.228247978593922),\n",
       " (1.6913037273647438, 0.1778355784649044),\n",
       " (1.9125336278023048, 36.7995449650502)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array([[j[0]] for j in s])\n",
    "y_test=np.array([j[1] for j in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    '''\n",
    "        基础线性回归模型，使用输入的X和y进行参数回归\n",
    "        超参\n",
    "        n_iterations:int 训练的步数\n",
    "        learning _rate:float 学习率\n",
    "        内部函数:\n",
    "        initialize_weights:初始化参数\n",
    "        fit开始训练\n",
    "        predict:预测\n",
    "        内部的数据\n",
    "        n_iterations\n",
    "        learning_rate\n",
    "        regularization:正则化参数\n",
    "        regularization.grad:正则化的梯度函数\n",
    "    '''\n",
    "    def __init__(self, n_iterations, learning_rate):\n",
    "        self.n_iterations=n_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization=lambda x:0\n",
    "        self.regularization.grad=lambda x:0\n",
    "    \n",
    "    def initialize_weights(self, n_features):\n",
    "        '''\n",
    "            初始化系数，输入是feature的个数，输出是一个随机初始化好的参数矩阵\n",
    "            [-1/sqrt(N),1/sqrt(N)]\n",
    "        '''\n",
    "        limit=1/math.sqrt(n_features)\n",
    "        self.w=np.random.uniform(-limit, limit, (n_features,))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # 插入偏置列1到X中\n",
    "        X=np.insert(X, 0,1, axis=1) # 给每一行的第0列增加一个1\n",
    "        self.training_errors=[] #保存每一步步长的训练Loss\n",
    "        self.initialize_weights(n_features=X.shape[1]) #初始化参数w\n",
    "        \n",
    "        # 进行梯度下降迭代\n",
    "        for i in range(self.n_iterations):\n",
    "            y_pred = X.dot(self.w) #进行预测\n",
    "            #计算Loss,做平均m个样本\n",
    "            mse = np.mean(0.5*(y-y_pred)**2 + self.regularization(self.w))\n",
    "            self.training_errors.append(mse) #将Loss键入到train_errors的数组中\n",
    "            # 计算带有正则化项的梯度\n",
    "            g_w = -(y-y_pred).T.dot(X)/len(X)+self.regularization.grad(self.w)\n",
    "            #根据梯度下降算法更新参数\n",
    "            self.w -= self.learning_rate*g_w\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 通过输入X预测一个样本\n",
    "        X = np.insert(X,0,1,axis=1)\n",
    "        pred=X.dot(self.w)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression(n_iterations=1000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Steps')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8XXWd//HXO0mbNknbNCQtTVtooQWsymaFMsiIIIjAgI46wjiKDsrPGec3OuPMiMrvB24zOgso4zKDgoPoyOIyMvwQpgIKKFsrBduytEChe9Ml3bckn98f55tyG7LcG3Jzk9z38/G4j9zzPeee8zn3tHnne1ZFBGZmZvmqKHUBZmY2vDg4zMysIA4OMzMriIPDzMwK4uAwM7OCODjMzKwgDg4DQNJpkp4pdR0jgaTDJO2QVFnqWnoj6QhJOwZ6Whv5HBxlRtIKSW/t2h4RD0TE0aWoqStJV0nan375tkr6jaRTSl1XviLipYioi4j2gZpnThh1vkLSzpzh0/pR5/MRUTfQ0xZK0vcl7euyfguLsSwbGA4OKylJVT2MuiX9omoE7gNuG+TlDyk5YVSX8wv8uJy2B7p+Zqj3eLr4+9z1i4g3dDdRd9ur0G04XLb5UObgMAAknS5pVc7wCkl/I+lJSVsl3SJpTM748yUtyukRHJsz7nJJz0naLmmppHfmjPugpF9LukbSJuCq3uqKiDbgB8BUSU15Lv9ESY+n5d+Wav9i7npK+pSkdcB385jfpyStTvN7RtKZqf0kSQskbZO0XtLVqX1G6hFUpeFmSbdL2ixpuaSP5Mz7Kkm3Svpemv8SSXPz3nA50l/u35B0l6SdwGmSLkjrtU3SS5L+T870syRFzvCDkj6X1n97mk9DodOm8R9Ky9so6TPpOz+9H+s0K32XH5L0EvA/3bWlad+Zvr9WSfdKOjpnPqsk/a2k3wE7C63DuogIv8roBawA3tpN++nAqi7TPQo0Aw3AU8BH07gTgA3AyUAlcEmavjqNf0/6XAXwXrL/qFPSuA8CbcD/BqqAsd3UchXw/fR+NPBlYCNQ1dfy0/QvAh8HRgF/COwDvpiznm3AV9L0Y/uY39HASqA5fX4GcGR6/xDw/vS+DpiXM03k1Hs/8E1gDHA80AKckbOue4Bz07L/AXg4j+0YwKwubd8HtgCnpO++GjgDeG0aPi59j+en6WcBkfP5B4FlwGygBngg53srZNrXA9uB30s1XJO+89N7WJfvA1f1MG5WWtfvpuWM7aHtNcCOtL6jgM8AzwCj0nxWAQuBaXTzb86vwl7ucVhvro2INRGxGfhvsl96AJcB/x4Rj0REe0TcCOwF5gFExG3pcx0RcQvZL5iTcua7JiL+NSLaImJ3D8v+I0mtwG7gI8C7I+t99LX8eWSBdG1E7I+In5AFYK4O4MqI2JuW39v82sl++c2RNCoiVkTEc2k++4FZkhojYkdEPNx1JSRNB04FPhUReyJiEfAd4AM5kz0YEXdGdkzkJrJf8P3104h4KH33eyPi3ohYkoafAG4G3tzL56+PiGURsYts9+Dx/Zj2PcB/RcRvImIvcEUedV+eegqdr+u7jL8yInZ1+feS23YRcHta3/1kf2xMIPtjoNPXImJVL//mLE8ODuvNupz3u8j+qgY4HPhk7n90YDpZLwNJH8jZ7dMKvI7sWEWnlXks+9aIqAcmA4uB3H3evS2/GVgdEbl37+y6vJaI2JPP/CJiOfAJsp7BBkk3S2pOn7sUOAp4WtJjks7vZj2agc0RsT2n7UVgas5w1+95jPq/H/6gdZV0iqRfSmqRtBX4MAdvi6562uaFTNucW0dE7CTrCfXmyxFRn/O6tMv47v7N5LY1k32vncvsIOtlTO1hensVHBzWHyuBL3X5j14TET+UdDjwbeAvgEPSL//FgHI+n/ctmSNiI1mP4CpJU/paPrCW7HhI7vKmd51tvuuTavjPiHgTWcAE2W4u0l/bFwOTUtuPJNV2mfcaoEHSuJy2w4DV+X4HBeq6bjcDPwamR8QEst6OXvGpgbWWbJcQAOk7mfhqZtjlD4Hu2taQbZ/OZVakGnK/Z98KfIA4OMrTKEljcl6F/nX7beCjkk5WplbSeemXYy3Zf9AWyA6SkvU4+i0ingHuBv4uj+U/RLZ76S8kVUm6kIN3kxW0PpKOlnSGpGqyYxG7yXZ1IelPJDWlv25b07w6utS+EvgN8A/puz6WrKfy/VfznRRgHFmPZ4+keWS7dIrtNuAdkuZJGg18fhCWeStwgbKTH0YBf0t2nOWRQVh22XFwlKc7yX4Bdr6uKuTDEbGA7LjD18l2QSwnO+hNRCwF/oXsF/h6sgOlvx6Amv8JuEzSpD6Wv4/sgPilZL/M/wS4g+yYRcHrQ3Z8o/Pg/Dqy3sWn07hzgCXKLoz7GnBRD/vPLyY7YL4G+CnZvvlfFLj+/fVnZKG1neyA8a3FXmBEPAn8FVmArAE2pVeP2wD4jA6+jmNdL9N2t8wlZCc1fIvsj5ZzgAvS8Q4bYOqmB2g2okh6BPi3iPhuqWspR5LGk4X44akHZsOcexw24kh6s6RD066qS4BjgbtKXVc5UXb9SI2kOrIe6G8dGiOHg8NGoqOBJ8j+yv0k2am8a0tbUtl5J9luqlVku+kuLmk1NqC8q8rMzAriHoeZmRVkRN7sq7GxMWbMmFHqMszMhpWFCxdujIimvqYbkcExY8YMFixYUOoyzMyGFUkv9j2Vd1WZmVmBHBxmZlYQB4eZmRXEwWFmZgVxcJiZWUEcHGZmVhAHh5mZFcTBkWN1626u/p9nWLHRz7I3M+uJgyPHlp37uPbe5Ty9bnvfE5uZlSkHR46G2tEAbNm1r8SVmJkNXQ6OHJ3BsXmng8PMrCcOjhxjRlVSM7rSwWFm1gsHRxcNtaMdHGZmvShqcEhaIel3khZJWpDaGiTNl7Qs/ZyY2iXpWknLJT0p6cSc+VySpl+WHgVaNA4OM7PeDUaP4y0RcXxEzE3DlwP3RMRs4J40DPB2YHZ6XQZ8C7KgAa4ETgZOAq7sDJticHCYmfWuFLuqLgRuTO9vBN6R0/69yDwM1EuaArwNmB8RmyNiCzAfOKdYxTXUODjMzHpT7OAI4H8kLZR0WWqbHBFr0/t1wOT0fiqwMuezq1JbT+0HkXSZpAWSFrS0tPS7YPc4zMx6V+wnAL4pIlZLmgTMl/R07siICEkxEAuKiOuA6wDmzp3b73lOrB3N7v3t7N7XztjRlQNRmpnZiFLUHkdErE4/NwA/JTtGsT7tgiL93JAmXw1Mz/n4tNTWU3tRHNJ5LYcvAjQz61bRgkNSraRxne+Bs4HFwO1A55lRlwA/S+9vBz6Qzq6aB2xNu7TuBs6WNDEdFD87tRXFgavHvbvKzKxbxdxVNRn4qaTO5fxnRNwl6THgVkmXAi8Cf5SmvxM4F1gO7AI+BBARmyV9AXgsTff5iNhcrKI7g2OTg8PMrFtFC46IeB44rpv2TcCZ3bQH8LEe5nUDcMNA19gd9zjMzHrnK8e7cI/DzKx3Do4uxo8ZRWWF3OMwM+uBg6OLigoxsWaUexxmZj1wcHSjoXa0exxmZj1wcHRjom87YmbWIwdHNw6pG+0LAM3MeuDg6IZ7HGZmPXNwdOOQ2tG07tpHe8eA3EbLzGxEcXB0Y2LtaDoCtu7eX+pSzMyGHAdHNw6pqwZg0469Ja7EzGzocXB0o7Euu3q8xcFhZvYKDo5uNKUex8YdPkBuZtaVg6MbjZ3Bsd09DjOzrhwc3ZgwdhRVFWKjd1WZmb2Cg6MbFRWisa6aFvc4zMxewcHRg8Zxo93jMDPrhoOjB4111T44bmbWDQdHD7LgcI/DzKwrB0cPOoMje6KtmZl1cnD0oGlcNfvbw7cdMTPrwsHRg86rx727yszsYA6OHnRePd6y3QfIzcxyOTh60Diu87Yj7nGYmeVycPTgwG1HHBxmZgdxcPSgfuwoKivkq8fNzLpwcPQgu+2Irx43M+vKwdELXz1uZvZKDo5e+OpxM7NXcnD0orGu2s/kMDPrwsHRi6Zx1bT4tiNmZgcpenBIqpT0uKQ70vBMSY9IWi7pFkmjU3t1Gl6exs/ImcenU/szkt5W7Jo7TR6f3XZkyy7fdsTMrNNg9Dg+DjyVM/wV4JqImAVsAS5N7ZcCW1L7NWk6JM0BLgJeC5wDfFNS5SDUzaHjxwCwbuuewVicmdmwUNTgkDQNOA/4ThoWcAbwozTJjcA70vsL0zBp/Jlp+guBmyNib0S8ACwHTipm3Z0mpeBYv93BYWbWqdg9jq8Cfwd0pOFDgNaIaEvDq4Cp6f1UYCVAGr81TX+gvZvPHCDpMkkLJC1oaWkZkOInj8+uHt+wzcFhZtapaMEh6XxgQ0QsLNYyckXEdRExNyLmNjU1Dcg8m9L9qtZv85lVZmadqoo471OBCySdC4wBxgNfA+olVaVexTRgdZp+NTAdWCWpCpgAbMpp75T7maKqrqqkoXY069zjMDM7oGg9joj4dERMi4gZZAe3742I9wH3Ae9Ok10C/Cy9vz0Nk8bfG9l5sLcDF6WzrmYCs4FHi1V3V5PHj/GuKjOzHMXscfTkU8DNkr4IPA5cn9qvB26StBzYTBY2RMQSSbcCS4E24GMR0T5YxU4eX+1dVWZmOQYlOCLil8Av0/vn6easqIjYA7ynh89/CfhS8Srs2eRxY1i6ZlspFm1mNiT5yvE+TB6f3a+qrb2j74nNzMqAg6MPk8aPoSPwXXLNzBIHRx86rx5f7wPkZmaAg6NPkx0cZmYHcXD0ofPq8fW+vbqZGeDg6NMhddVUCNb7RodmZoCDo0+VFaJpXLV3VZmZJQ6OPBw6fox3VZmZJQ6OPEweP4a1rbtLXYaZ2ZDg4MhDc/1Y1voYh5kZ4ODIS3P9GHbsbWPbHj9C1szMwZGH5vqxAKzx7iozMwdHPqZMyIJjbat3V5mZOTjyMDX1OFa7x2Fm5uDIR9O4aqoq5F1VZmY4OPJSWaHslFyfWWVm5uDI19T6sd5VZWaGgyNvU+rHsHarg8PMzMGRp+b6sazbuof2jih1KWZmJeXgyFNz/Vj2twcbd/ieVWZW3hwceWqekD3QyWdWmVm5c3Dk6eWrx31mlZmVtz6DQ9I8STXp/cWS/lHS9OKXNrQ0d1497gPkZlbm8ulxXAfslnQs8ClgNXBTUasagsaPraJ2dCWrtjg4zKy85RMcbRERwIXA1yPia8D44pY19Ehi2sQaX8thZmWvKo9pdkr6W+BPgNMlVQCjilvW0DS9YSwrN+8qdRlmZiWVT4/jvYCAj0bEWmAacHVRqxqipjfUsHLzLrIOmJlZecqnx7EF+OeI6JB0JHA0ZXiMA2D6xBp27mtn8859HFJXXepyzMxKIp8exwPAGElTgHuBjwA3FLWqIeqwhhoAVvoAuZmVsXyCoyIidgHvAr4VEe8EjituWUPT9BQcL/k4h5mVsbyCQ9IbgfcBd+T7OUljJD0q6QlJSyR9LrXPlPSIpOWSbpE0OrVXp+HlafyMnHl9OrU/I+ltha7kQJnekF3L4QPkZlbO8gmOvwY+B9wREYslHUG2+6ove4EzIuI44HjgHEnzgK8A10TELLLjJ5em6S8FtqT2a9J0SJoDXAS8FjgH+KakynxXcCDVjK6isa7awWFmZa3P4IiIeyPiXOBqSWMj4vmI+PM8PhcRsSMNjkqvAM4AfpTabwTekd5fmIZJ48+UpNR+c0TsjYgXgOXASfmt3sCb3jDWu6rMrKzls8tpjqTHgGVA526k1+Qzc0mVkhYBG4D5wHNAa0S0pUlWAVPT+6nASoA0fitwSG57N5/JXdZlkhZIWtDS0pJPef1yWEMNK7c4OMysfOV7y5HPRMS0iJgKfBb4dj4zj4j2iDie7NqPk4Bj+l1p38u6LiLmRsTcpqamYi2G6RNrWNO6h7b2jqItw8xsKMsnOMZFxPzOgYj4BTCukIVERCtwH3AKUC+p8/qRaWT3viL9nA6Qxk8ANuW2d/OZQXdYQw3tHeHnj5tZ2conOFaks5qmpdflwIq+PiSpSVJ9ej8WOAt4iixA3p0muwT4WXp/exomjb833SPrduCidNbVTGA28Ghea1cE09KZVT7OYWblKp8rx/8U+AJwJ9nB7QeAD+XxuSnAjekMqArg1oi4Q9JS4GZJXwQeB65P018P3CRpObCZ7EwqImKJpFuBpUAb8LGIaM93BQfaYTnXcpxaqiLMzEqoz+CIiE3AQWdRSfoycHkfn3sSOKGb9ufp5qyoiNgDvKeHeX0J+FJftQ6GKRPGMrqyghWbdpa6FDOzkujvEwD/eECrGEYqK8Thh9TwQouDw8zKU3+DQwNaxTAzo7GWFzY6OMysPPW4q0pSTw9rKuvQADiisZZfPdNCe0dQWVH2X4eZlZnejnEsITsY3t1vxrJ+IMXMxlr2tXewpnX3gRsfmpmVix6DIyKm9zSu3M1srAXghY07HRxmVnYKOsYh6YpiFTKczGx6OTjMzMpNoQfH/7AoVQwzTXXV1FVXOTjMrCwVGhw+EgxIYkZjDc87OMysDBUaHCW7nflQM7Oxjhc27uh7QjOzEabPK8clNZLddmQGUJU9IgMi4rKiVjbEzWys5Y4n17C3rZ3qqpI8V8rMrCTyuVfVz4CHgQeBkt0jaqg5orGWCHhp0y5mTy7oZsFmZsNaPsFRGxGfLHolw8wR6cyq51p2ODjMrKzkc4zj55LOLnolw8yRTXUAPLvexznMrLzkExwfBe6StEPSZklbJG0udmFDXW11FdMmjuXZ9dtLXYqZ2aDKZ1dVY9GrGKaOmjyO5Rvc4zCz8tLbTQ5nR8Qy4LU9TPJkcUoaPmZPruPBZRtpa++gqrK/Nxo2MxteeutxXA5cCnyjm3EB/H5RKhpGjpo0jn3tHazYtItZk+pKXY6Z2aDo7SaHl6afpw1eOcPL7MlZWCxbv93BYWZlI59jHEg6BpgDjOlsi4j/LFZRw0VnWDy7fgdvf32JizEzGyT5XDl+BXA2cAxwN/A2sosByz44akZXMb1hLMs2+MwqMysf+RzRfS/wFmBtRLwfOA6oLWpVw8hRk8axzNdymFkZySc4dkdEO9AmaRywDji8uGUNH7Mnj+P5jTvY395R6lLMzAZFPsHxuKR64AZgAfBoehlwzKHj2N8ePN/iW6ybWXno9RiHslvhXhURrcA3JN0NjI+I3w5KdcPAnObxACxdu5WjD/U9q8xs5Ou1xxERAczPGV7u0DjYEY21VFdVsHTNtlKXYmY2KPLZVbVI0glFr2SYqqqs4JhDx7F0rYPDzMpDb7ccqYqINuAE4DFJzwE7yR4fGxFx4iDVOOTNaR7PzxevIyLofNCVmdlI1dsxjkeBE4ELBqmWYWvOlPH88NGVrN26h+b6saUux8ysqHoLDgFExHODVMuwNad5AgBL1mxzcJjZiNdbcDRJ+uueRkbE1UWoZ1g65tBxSLB0zTbOmjO51OWYmRVVbwfHK4E6YFwPr15Jmi7pPklLJS2R9PHU3iBpvqRl6efE1C5J10paLulJSSfmzOuSNP0ySZf0f3WLo7a6ipmNtSxdu7XUpZiZFV1vPY61EfH5VzHvNuCTEfHbdMX5QknzgQ8C90TElyVdTnb79k8Bbwdmp9fJwLeAkyU1AFcCc8lu575Q0u0RseVV1Dbg5kwZz+MvtZa6DDOzouutx/GqTg+KiLWd13xExHbgKWAqcCFwY5rsRuAd6f2FwPci8zBQL2kK2U0V50fE5hQW84FzXk1txXDstAmsbt3Nph17S12KmVlR9RYcZw7UQiTNIDut9xFgckSsTaPWAZ0HBaYCK3M+tiq19dQ+pBw3rR6AJ1a512FmI1uPwRERmwdiAZLqgB8Dn4iIg66SS1emxwAt5zJJCyQtaGlpGYhZFuT10yZQWSEWeXeVmY1wRX1QtqRRZKHxg4j4SWpen3ZBkX5uSO2rgek5H5+W2npqP0hEXBcRcyNiblNT08CuSB5qRldx1ORxPL7SwWFmI1vRgiPdIPF64Kkup+7eDnSeGXUJ8LOc9g+ks6vmAVvTLq27gbMlTUxnYJ2d2oac46fX88TKVjo6BqQTZWY2JBWzx3Eq8H7gDEmL0utc4MvAWZKWAW9NwwB3As8Dy4FvA38OB3aZfQF4LL0+P1C70Qba8dMnsG1PGys2+RbrZjZy5fXM8f6IiAfp+cysVxx4T8c7PtbDvG4gex7IkHb89IkALFrZyhFNdSWuxsysOIp6jKPczJpUR+3oShb5OIeZjWAOjgFUWSGOnVbPb18aUtcmmpkNKAfHAHvjzAaWrtnG9j37S12KmVlRODgG2MkzG+gIWPiiex1mNjI5OAbYCYfVU1UhHn1hSJ74ZWb2qjk4BljN6CpeP22Cg8PMRiwHRxGcNLOBJ1a1smd/e6lLMTMbcA6OIjh5ZgP728O3WTezEcnBUQRvOLwBCR55YVOpSzEzG3AOjiKYMHYUr20ez2+WOzjMbORxcBTJabOb+O1LW9ixt63UpZiZDSgHR5GcNruRto7g4efc6zCzkcXBUSRvOHwiY0dV8sCywX+olJlZMTk4iqS6qpJ5RzTwwLKNpS7FzGxAOTiK6LTZTTy/cScrN+8qdSlmZgPGwVFEv39UIwD3e3eVmY0gDo4iOrKpjukNY/nF0vWlLsXMbMA4OIpIEme95lB+/dwmdvq0XDMbIRwcRXbWnMnsa+vg/me9u8rMRgYHR5G9ccZE6mtGMd+7q8xshHBwFFlVZQVnHD2Je5/ZQFt7R6nLMTN71Rwcg+Ds106mddd+HvEzOsxsBHBwDILTj55E7ehKbl+0ptSlmJm9ag6OQTBmVCVve+2h/HzxWva2+eFOZja8OTgGyR8c38y2PW386hmfXWVmw5uDY5C8aVYjDbWjuf0J764ys+HNwTFIRlVWcO7rD+UXT61n+579pS7HzKzfHByD6F0nTmPP/g73OsxsWHNwDKLjp9dzzKHjuPnRlaUuxcys3xwcg0gSF71xOr9bvZXFq7eWuhwzs34pWnBIukHSBkmLc9oaJM2XtCz9nJjaJelaScslPSnpxJzPXJKmXybpkmLVO1jeecI0qqsquPmxl0pdiplZvxSzx/EfwDld2i4H7omI2cA9aRjg7cDs9LoM+BZkQQNcCZwMnARc2Rk2w9WEmlGc9/op/Nfja9jmg+RmNgwVLTgi4n6g6z02LgRuTO9vBN6R0/69yDwM1EuaArwNmB8RmyNiCzCfV4bRsPPBU2ewY28btz7mYx1mNvwM9jGOyRGxNr1fB0xO76cCub9FV6W2ntqHtWOn1XPSzAa+++sVvvGhmQ07JTs4HhEBxEDNT9JlkhZIWtDSMvSvzv7wm2ayunU3dy1ZV+pSzMwKMtjBsT7tgiL93JDaVwPTc6abltp6an+FiLguIuZGxNympqYBL3ygnfmaycxsrOXffvUcWYaamQ0Pgx0ctwOdZ0ZdAvwsp/0D6eyqecDWtEvrbuBsSRPTQfGzU9uwV1kh/uz0I1m8epsf8mRmw0oxT8f9IfAQcLSkVZIuBb4MnCVpGfDWNAxwJ/A8sBz4NvDnABGxGfgC8Fh6fT61jQh/eMJUDj+khq/+Ypl7HWY2bFQVa8YRcXEPo87sZtoAPtbDfG4AbhjA0oaMqsoK/vKM2Xzytie4e8k6znndlFKXZGbWJ185XmIXHt/MkU21fOWuZ9jX5jOszGzoc3CUWFVlBVecP4cXNu7kxt+sKHU5ZmZ9cnAMAW85ehKnH93EtfcsY+OOvaUux8ysVw6OIeKK8+awe387X/n506UuxcysVw6OIWLWpDo+fNoR3LZwFfc/O/QvYDSz8uXgGEI+8dbZHNlUy+U/ftJPCTSzIcvBMYSMGVXJP73nONZt28MX73iq1OWYmXXLwTHEnHjYRP7Xm4/klgUr+enjq0pdjpnZKzg4hqBPnnUUJ81o4DM/Wcyz67eXuhwzs4M4OIagqsoKvv7HJ1BbXcVHb1pI6659pS7JzOwAB8cQNWn8GL75vhNZtWU3H/neAvbsby91SWZmgINjSDtpZgNXv/c4Hluxhb+6ZZEf+mRmQ4KDY4g7/9hmrjjvNfx88Tr+6tYnHB5mVnJFuzuuDZwPn3YEbR3Bl3/+NG3tHXz1ouOprqosdVlmVqbc4xgmPvrmI/k/58/h54vX8f7vPMrmnT5gbmal4eAYRi5900yuvfgEFq1q5R3f+LVP1TWzknBwDDMXHNfMLZfNY9e+di74+oP84JEX/fRAMxtUDo5h6ITDJnLnX76JN85o4LM/XcxHvreQtVt3l7osMysTDo5hatL4Mdz4oZO44rzX8MCyFs78l19x3f3Psd9nXZlZkTk4hrGKCvHh047gF3/9Zk454hD+/s6nOfNffsWPFq7yabtmVjQOjhFgekMN13/wjXz3g29k3Jgq/ua2Jzjrmvu56aEV7NjbVuryzGyE0Ug8sDp37txYsGBBqcsoiYjg7iXr+cZ9y/nd6q3UVVfxrhOn8q43TOP1UycgqdQlmtkQJWlhRMztczoHx8gUETy+spWbHnqR//fkWva1d3BYQw3nHzuFM18zmeOmTaCq0h1OM3uZg6PMgyPX1l37uXvJOv77yTX85rlNtHcE48dUceqsRn7vyEM4fvpEjpkyjlEOErOy5uBwcHSrddc+Hly+kfufbeH+ZzeybtseAKqrKnjd1Am8rnk8syaPY/akOmZPquOQuuoSV2xmgyXf4PC9qspMfc1ozj+2mfOPbSYiWN26m8dfamXRylYef2kLP1q4ip37Xr6F+8SaUUybWENz/Ria68cytX4szfVjaayrpqF2FA211UwYO4rKCh87MSsXDo4yJolpE2uYNrGGPziuGciOjazduoflG3awbMMOnmvZwZrW3bywcScPLtt4UKi8PB+oHzuKhtrRTBg7itrqKuqqq6gZXUVddSW11VUH2saMqmB0VQWjKyuzn1UVjK7s8jO9KiUqKqBSorJCVFTo5fcHfuID/maDzMFhB5FEc+pV/P5RTQeNiwi27W5jdetuNu/cx6ade9mycx+bd+1n8869bNm5n62797N9Txvrtu5h1752duxtY+feNto6irdLtEJQoa7Bkq1LZ6aIlwPdrpJjAAAHM0lEQVQme39gjbtMc6AVKWuDg8NJeuV0ucsYsjE2BAsbgiUBQ/OPkXwrOv3oJj573pyi1uLgsLxJYkLNKCbUjCrocxHBvvYOdu5tZ/f+dva1dbz8au/ys62Dfe3ZNO0d0B5BR0fQ3hF0RPbz5bZsfHTT3pHaAQLoPJQXRM77l9tJ7X1NF0TWcKD94GUM1SOGQ/FY5tCrKBmChUUBRU0eP6aIlWQcHFZ0kqiuqvQzRMxGiGFz/qWkcyQ9I2m5pMtLXY+ZWbkaFsEhqRL4BvB2YA5wsaTi7sQzM7NuDYvgAE4ClkfE8xGxD7gZuLDENZmZlaXhEhxTgZU5w6tSm5mZDbLhEhx9knSZpAWSFrS0tJS6HDOzEWu4BMdqYHrO8LTUdkBEXBcRcyNiblPTwdcfmJnZwBkuwfEYMFvSTEmjgYuA20tck5lZWRoW13FERJukvwDuBiqBGyJiSYnLMjMrSyPy7riSWoAXX8UsGoGNA1TOcFBu6wte53LhdS7M4RHR577+ERkcr5akBfncWnikKLf1Ba9zufA6F8dwOcZhZmZDhIPDzMwK4uDo3nWlLmCQldv6gte5XHidi8DHOMzMrCDucZiZWUEcHGZmVhAHR46R+swPSdMl3SdpqaQlkj6e2hskzZe0LP2cmNol6dr0PTwp6cTSrkH/SKqU9LikO9LwTEmPpPW6Jd2FAEnVaXh5Gj+jlHW/GpLqJf1I0tOSnpJ0Shls579K/64XS/qhpDEjbVtLukHSBkmLc9oK3q6SLknTL5N0SX/rcXAkI/yZH23AJyNiDjAP+Fhat8uBeyJiNnBPGobsO5idXpcB3xr8kgfEx4Gncoa/AlwTEbOALcClqf1SYEtqvyZNN1x9DbgrIo4BjiNb/xG7nSVNBf4SmBsRryO7s8RFjLxt/R/AOV3aCtqukhqAK4GTyR5VcWVn2BQs0rOZy/0FnALcnTP8aeDTpa6rSOv6M+As4BlgSmqbAjyT3v87cHHO9AemGy4vshth3gOcAdwBiOxq2qqu25vsVjanpPdVaTqVeh36sc4TgBe61j7Ct3PnIxca0ra7A3jbSNzWwAxgcX+3K3Ax8O857QdNV8jLPY6XlcUzP1LX/ATgEWByRKxNo9YBk9P7kfBdfBX4O6AjDR8CtEZEWxrOXacD65vGb03TDzczgRbgu2kX3Xck1TKCt3NErAb+GXgJWEu27RYy8rc1FL5dB2x7OzjKiKQ64MfAJyJiW+64yP4EGRHnZks6H9gQEQtLXcsgqwJOBL4VEScAO3l59wUwsrYzQNrVciFZaDYDtbxyl86IN9jb1cHxsj6f+TGcSRpFFho/iIifpOb1kqak8VOADal9uH8XpwIXSFpB9pjhM8j2/ddL6rwjdO46HVjfNH4CsGkwCx4gq4BVEfFIGv4RWZCM1O0M8FbghYhoiYj9wE/Itv9I39ZQ+HYdsO3t4HjZiH3mhyQB1wNPRcTVOaNuBzrPrLiE7NhHZ/sH0tkZ84CtOV3iIS8iPh0R0yJiBtl2vDci3gfcB7w7TdZ1fTu/h3en6YfdX+URsQ5YKeno1HQmsJQRup2Tl4B5kmrSv/POdR7R2zopdLveDZwtaWLqqZ2d2gpX6gM+Q+kFnAs8CzwHfLbU9Qzger2JrBv7JLAovc4l27d7D7AM+AXQkKYX2RlmzwG/IztjpeTr0c91Px24I70/AngUWA7cBlSn9jFpeHkaf0Sp634V63s8sCBt6/8CJo707Qx8DngaWAzcBFSPtG0N/JDsGM5+sp7lpf3ZrsCfpnVfDnyov/X4liNmZlYQ76oyM7OCODjMzKwgDg4zMyuIg8PMzAri4DAzs4I4OMxeBUmfTXdmfVLSIkknS/qEpJpS12ZWLD4d16yfJJ0CXA2cHhF7JTUCo4HfkJ07v7GkBZoViXscZv03BdgYEXsBUlC8m+yeSfdJug9A0tmSHpL0W0m3pXuGIWmFpH+U9DtJj0qaldrfk54t8YSk+0uzamY9c4/DrJ9SADwI1JBduXtLRPwq3SNrbkRsTL2QnwBvj4idkj5FdhXz59N0346IL0n6APBHEXG+pN8B50TEakn1EdFakhU064F7HGb9FBE7gDeQPSynBbhF0ge7TDaP7MFgv5a0iOyeQofnjP9hzs9T0vtfA/8h6SNkDyYyG1Kq+p7EzHoSEe3AL4Ffpp5C18dxCpgfERf3NIuu7yPio5JOBs4DFkp6Q0QM1zu42gjkHodZP0k6WtLsnKbjgReB7cC41PYwcGrO8YtaSUflfOa9OT8fStMcGRGPRMT/JevJ5N4K26zk3OMw67864F8l1ZM913052W6ri4G7JK2JiLek3Vc/lFSdPncF2V2YASZKehLYmz4H8E8pkER299MnBmVtzPLkg+NmJZJ7EL3UtZgVwruqzMysIO5xmJlZQdzjMDOzgjg4zMysIA4OMzMriIPDzMwK4uAwM7OC/H8fLYOK4yZUvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b843940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training=plt.plot(range(len(model.training_errors)), model.training_errors, label=\"Training Error\")\n",
    "plt.title(\"Linear Regression Training Error\")\n",
    "plt.ylabel(\"Train-Loss\")\n",
    "plt.xlabel(\"Steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_draw:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396.79807737274433"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带有最小二乘法的线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsm_function(X, y):\n",
    "    G=np.mat(np.insert(X, 0, 1, axis=1))\n",
    "    return np.squeeze(np.asarray((G.T.dot(G)).I.dot(G.T).dot(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51332197, 99.43413383])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm_function(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(Regression):\n",
    "    '''\n",
    "    带有最小二乘法的线性回归\n",
    "    参数：\n",
    "    --------------------\n",
    "    n_iterations\n",
    "    \n",
    "    learning_rate\n",
    "    \n",
    "    \n",
    "    gradient_descent:bool\n",
    "        决定是否使用梯度下降法\n",
    "        True 使用梯度下降\n",
    "        False 使用最小二乘法\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_iterations=500, learning_rate=0.1, gradient_descent=True):\n",
    "        self.gradient_descent=gradient_descent\n",
    "        self.regularization=lambda x:0\n",
    "        self.regularization.grad=lambda x:0\n",
    "        super(LinearRegression,self).__init__(n_iterations=n_iterations,learning_rate=learning_rate)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if not self.gradient_descent:\n",
    "            self.w=lsm_function(X, y)\n",
    "        else:\n",
    "            super(LinearRegression, self).fit(X, y)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return super(LinearRegression, self).predict(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(n_iterations=1000, learning_rate=0.1, gradient_descent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51332197, 99.43413383])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class l1_regularization():\n",
    "    '''\n",
    "    L1正则化/函数\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        return self.alpha*np.linalg.norm(w, ord=1)\n",
    "    \n",
    "    def grad(self, w):\n",
    "        # w>0->w`=1; w<0->w`=0; w==0->w`=0\n",
    "        return self.alpha*np.sign(w)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=l1_regularization(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1([-3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01,  0.01,  0.  ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.grad([-3, 4, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2正则化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class l2_regularization():\n",
    "    '''\n",
    "    L2正则化参数\n",
    "    参数：\n",
    "        alpha 正则化系数\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __call__(self, w):\n",
    "        return self.alpha*0.5 * w.T.dot(w)\n",
    "    \n",
    "    def grad():\n",
    "        return self.alpha * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = l2_regularization(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-edbc8c6d8be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-772f71a17e4f>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "l2([-3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoLinearRegression(Regression):\n",
    "    def __init__(self, alpha, n_iterations=1000, learning_rate=0.01):\n",
    "        self.regularization = l1_regularization(alpha=alpha)\n",
    "        super(LassoLinearRegression, self).__init__(n_iterations, learning_rate)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        super(LassoLinearRegression, self).fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return super(LassoLinearRegression, self).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LassoLinearRegression(alpha=1.2, n_iterations=10000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51332197, 99.43413383])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_and_draw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d0c2b4d6716d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_and_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_and_draw' is not defined"
     ]
    }
   ],
   "source": [
    "test_and_draw(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
