{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import*\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正常的处理方案\n",
    "# 两个参数：第一个参数==> dataMatIn 是一个2维NumPy数组，每列分别代表每个不同的特征，每行则代表每个训练样本。\n",
    "# 第二个参数==> classLabels 是类别标签，它是一个 1*100 的行向量。为了便于矩阵计算，需要将该行向量转换为列向量，做法是将原向量转置，再将它赋值给labelMat。\n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    # 转化为矩阵[[1,1,2],[1,1,2]....]\n",
    "    dataMatrix = mat(dataMatIn)  # 转换为 NumPy 矩阵\n",
    "    # 转化为矩阵[[0,1,0,1,0,1.....]]，并转制[[0],[1],[0].....]\n",
    "    # transpose() 行列转置函数\n",
    "    # 将行向量转化为列向量   =>  矩阵的转置\n",
    "    labelMat = mat(classLabels).transpose() # 首先将数组转换为 NumPy 矩阵，然后再将行向量转置为列向量    \n",
    "    # m->数据量，样本数 n->特征数    \n",
    "    m,n = shape(dataMatrix)    \n",
    "    # print m, n, '__'*10, shape(dataMatrix.transpose()), '__'*100    \n",
    "    # alpha代表向目标移动的步长    \n",
    "    alpha = 0.001    \n",
    "    # 迭代次数    \n",
    "    maxCycles = 500    \n",
    "    # 生成一个长度和特征数相同的矩阵，此处n为3 -> [[1],[1],[1]]    \n",
    "    # weights 代表回归系数， 此处的 ones((n,1)) 创建一个长度和特征数相同的矩阵，其中的数全部都是 1    \n",
    "    weights = ones((n,1))    \n",
    "    for k in range(maxCycles):\n",
    "        #heavy on matrix operations\n",
    "        # m*3 的矩阵 * 3*1 的单位矩阵 ＝ m*1的矩阵\n",
    "        # 那么乘上单位矩阵的意义，就代表：通过公式得到的理论值\n",
    "        # 参考地址： 矩阵乘法的本质是什么？ https://www.zhihu.com/question/21351965/answer/31050145\n",
    "        # print 'dataMatrix====', dataMatrix\n",
    "        # print 'weights====', weights\n",
    "        # n*3   *  3*1  = n*1\n",
    "        h = sigmoid(dataMatrix*weights) # 矩阵乘法\n",
    "        # print 'hhhhhhh====', h\n",
    "        # labelMat是实际值\n",
    "        error = (labelMat - h) # 向量相减\n",
    "        # 0.001* (3*m)*(m*1) 表示在每一个列上的一个误差情况，最后得出 x1,x2,xn的系数的偏移量\n",
    "        weights = weights + alpha * dataMatrix.transpose() * error\n",
    "\n",
    "    # 矩阵乘法，最后得到回归系数\n",
    "    return array(weights)\n",
    "\n",
    "# 随机梯度上升\n",
    "# 梯度上升优化算法在每次更新数据集时都需要遍历整个数据集，计算复杂都较高# 随机梯度上升一次只用一个样本点来更新回归系数\n",
    "def stocGradAscent0(dataMatrix, classLabels):\n",
    "    m,n = shape(dataMatrix)\n",
    "    alpha = 0.01    # n*1的矩阵\n",
    "    # 函数ones创建一个全1的数组\n",
    "    weights = ones(n) # 初始化长度为n的数组，元素全部为 1\n",
    "    for i in range(m):\n",
    "        # sum(dataMatrix[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn,此处求出的 h 是一个具体的数值，而不是一个矩阵\n",
    "        h = sigmoid(sum(dataMatrix[i]*weights))\n",
    "        # print 'dataMatrix[i]===', dataMatrix[i]\n",
    "        # 计算真实类别与预测类别之间的差值，然后按照该差值调整回归系数\n",
    "        error = classLabels[i] - h\n",
    "        # 0.01*(1*1)*(1*n)\n",
    "        # print weights, \"*\"*10 , dataMatrix[i], \"*\"*10 , error\n",
    "        weights = weights + alpha * error * dataMatrix[i]\n",
    "\n",
    "    return weights\n",
    "    \n",
    "    \n",
    "# 随机梯度上升算法（随机化）\n",
    "def stocGradAscent1(dataMatrix, classLabels, numIter=150):\n",
    "    m,n = shape(dataMatrix)\n",
    "    weights = ones(n)   # 创建与列数相同的矩阵的系数矩阵，所有的元素都是1\n",
    "    # 随机梯度, 循环150,观察是否收敛\n",
    "    for j in range(numIter):\n",
    "        # [0, 1, 2 .. m-1]\n",
    "        dataIndex = list(range(m))\n",
    "        for i in range(m):\n",
    "            # i和j的不断增大，导致alpha的值不断减少，但是不为0\n",
    "            alpha = 4/(1.0+j+i)+0.0001\n",
    "            # alpha 会随着迭代不断减小，但永远不会减小到0，因为后边还有一个常数项0.0001\n",
    "            # 随机产生一个 0～len()之间的一个值\n",
    "            # random.uniform(x, y) 方法将随机生成下一个实数，它在[x,y]范围内,x是这个范围内的最小值，y是这个范围内的最大值。\n",
    "            randIndex = int(random.uniform(0,len(dataIndex)))\n",
    "            # sum(dataMatrix[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn\n",
    "            h = sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error = classLabels[randIndex] - h\n",
    "            # print weights, '__h=%s' % h, '__'*20, alpha, '__'*20, error, '__'*20, dataMatrix[randIndex]\n",
    "            weights = weights + alpha * error * dataMatrix[randIndex]\n",
    "            del(dataIndex[randIndex])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "# 分类函数，根据回归系数和特征向量来计算 Sigmoid的值\n",
    "def classifyVector(inX, weights):\n",
    "    '''\n",
    "    Desc:\n",
    "        最终的分类函数，根据回归系数和特征向量来计算 Sigmoid 的值，大于0.5函数返回1，否则返回0    \n",
    "    Args:        \n",
    "        inX -- 特征向量，features        \n",
    "        weights -- 根据梯度下降/随机梯度下降 计算得到的回归系数    \n",
    "    Returns:\n",
    "        如果 prob 计算大于 0.5 函数返回 1\n",
    "        否则返回 0\n",
    "    '''\n",
    "    prob = sigmoid(sum(inX*weights))\n",
    "    if prob > 0.5:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "# 打开测试集和训练集,并对数据进行格式化处理\n",
    "def colicTest():\n",
    "    '''    \n",
    "    Desc:        打开测试集和训练集，并对数据进行格式化处理    \n",
    "    Args:        None\n",
    "    Returns:\n",
    "        errorRate -- 分类错误率\n",
    "    '''\n",
    "    frTrain = open('5.Logistic/HorseColicTraining.txt')\n",
    "    frTest = open('5.Logistic/HorseColicTest.txt')\n",
    "    trainingSet = []\n",
    "    trainingLabels = []\n",
    "    # 解析训练数据集中的数据特征和Labels\n",
    "    # trainingSet 中存储训练数据集的特征，trainingLabels 存储训练数据集的样本对应的分类标签\n",
    "    for line in frTrain.readlines():\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr = []\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        trainingSet.append(lineArr)\n",
    "        trainingLabels.append(float(currLine[21]))\n",
    "    \n",
    "    # 使用 改进后的 随机梯度下降算法 求得在此数据集上的最佳回归系数 trainWeights\n",
    "    trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, 500)\n",
    "    errorCount = 0\n",
    "    numTestVec = 0.0\n",
    "    # 读取 测试数据集 进行测试，计算分类错误的样本条数和最终的错误率\n",
    "    for line in frTest.readlines():\n",
    "        numTestVec += 1.0\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr = []\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        if int(classifyVector(array(lineArr), trainWeights)) != int(currLine[21]):\n",
    "            errorCount += 1\n",
    "    errorRate = (float(errorCount) / numTestVec)\n",
    "    print(\"the error rate of this test is: %f\" % errorRate)\n",
    "    \n",
    "    return errorRate\n",
    "\n",
    "\n",
    "# 调用 colicTest() 10次并求结果的平均值\n",
    "def multiTest():\n",
    "    numTests = 10\n",
    "    errorSum = 0.0\n",
    "    for k in range(numTests):\n",
    "        errorSum += colicTest()\n",
    "    print(\"after %d iterations the average error rate is: %f\" %(numTests, errorSum/float(numTests)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate of this test is: 0.298507\n",
      "the error rate of this test is: 0.358209\n",
      "the error rate of this test is: 0.313433\n",
      "the error rate of this test is: 0.417910\n",
      "the error rate of this test is: 0.358209\n",
      "the error rate of this test is: 0.313433\n",
      "the error rate of this test is: 0.313433\n",
      "the error rate of this test is: 0.268657\n",
      "the error rate of this test is: 0.313433\n",
      "the error rate of this test is: 0.313433\n",
      "after 10 iterations the average error rate is: 0.326866\n"
     ]
    }
   ],
   "source": [
    "multiTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
